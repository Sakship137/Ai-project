# -*- coding: utf-8 -*-
"""FoodDetectorFinal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OfVU2N2C3fjjpbD27VEzJDKduOlMC4c2
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive

!pip install huggingface_hub

!huggingface-cli login

"""Downloads the raw repository structure and the 7.5 GB of images/labels into a single folder on my Drive. This bypasses the old git lfs process, by using snapshot we ensure that we get all data required for training.
On using git lfs i was able to fetch only 50 mb data from repository, snapshot helped me to fetch 7.5 GB Yolo dataset.
"""

from huggingface_hub import snapshot_download
import os

print("Starting the 7.5 GB dataset download...")
print("This will take a long time. Please be patient.")

# This is the name of the folder it will create in your Google Drive
dataset_folder_name = "sohl-multidish-yolo-dataset-v2"

snapshot_download(
    repo_id="SohlHealth/sohl-multidish-yolo-dataset",
    repo_type="dataset",
    local_dir=dataset_folder_name,      # Saves to /content/drive/MyDrive/sohl-multidish-yolo-dataset-v2
    local_dir_use_symlinks=False  # This is important for Google Drive
)

print("---")
print(f"Download complete! The dataset is now in a folder named: {dataset_folder_name}")
print("---")

!ls -l /content/drive/MyDrive/sohl-multidish-yolo-dataset-v2/images

!ls -l /content/drive/MyDrive/sohl-multidish-yolo-dataset-v2/labels | head -n 10

"""Reads image names , randomly shuffles them, and moves 80% of the corresponding image/label files into train/ folders and 20% into val/ folders.




**YOLO Requirement**
Unlike CatBoost(which use cross-validation) , Deep Learning models require a seperate, dedicated validation set (val) to monitor training profess and prevent ***overfitting***.

"""

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# 
# # 1. Create the main new dataset folder
# mkdir /content/drive/MyDrive/sohl-dataset-split
# 
# # 2. Create the images folder and its subfolders
# mkdir /content/drive/MyDrive/sohl-dataset-split/images
# mkdir /content/drive/MyDrive/sohl-dataset-split/images/train
# mkdir /content/drive/MyDrive/sohl-dataset-split/images/val
# 
# # 3. Create the labels folder and its subfolders
# mkdir /content/drive/MyDrive/sohl-dataset-split/labels
# mkdir /content/drive/MyDrive/sohl-dataset-split/labels/train
# mkdir /content/drive/MyDrive/sohl-dataset-split/labels/val

import os
import glob
import random
import shutil

# --- 1. DEFINE ALL OUR PATHS ---

# The folder with all the original downloaded images
SOURCE_IMAGES_DIR = "/content/drive/MyDrive/sohl-multidish-yolo-dataset-v2/images"

# The folder with all the original downloaded labels
SOURCE_LABELS_DIR = "/content/drive/MyDrive/sohl-multidish-yolo-dataset-v2/labels"

# The new folders we just created
TRAIN_IMG_DEST = "/content/drive/MyDrive/sohl-dataset-split/images/train"
VAL_IMG_DEST = "/content/drive/MyDrive/sohl-dataset-split/images/val"
TRAIN_LABEL_DEST = "/content/drive/MyDrive/sohl-dataset-split/labels/train"
VAL_LABEL_DEST = "/content/drive/MyDrive/sohl-dataset-split/labels/val"

# --- 2. SET OUR TRAIN/VAL SPLIT (80% train, 20% val) ---
VAL_SPLIT_PERCENT = 0.20

# --- 3. GET A LIST OF ALL IMAGES ---
# This looks for every file ending in .jpg in the source folder
all_images = glob.glob(os.path.join(SOURCE_IMAGES_DIR, "*.jpg"))

# Shuffle the list to make it random
random.shuffle(all_images)

# --- 4. CALCULATE THE SPLIT ---
total_images = len(all_images)
split_index = int(total_images * (1 - VAL_SPLIT_PERCENT))

# Split the list into two new lists
train_images = all_images[:split_index]
val_images = all_images[split_index:]

print(f"Total images: {total_images}")
print(f"Moving {len(train_images)} images to training set.")
print(f"Moving {len(val_images)} images to validation set.")

# --- 5. FUNCTION TO MOVE THE FILES ---
def move_files(file_list, img_dest, label_dest):
    for img_path in file_list:
        # Get the filename (e.g., "image1.jpg")
        img_filename = os.path.basename(img_path)

        # Get the label filename (e.g., "image1.txt")
        label_filename = os.path.splitext(img_filename)[0] + ".txt"

        # Get the full path to the label file
        label_path = os.path.join(SOURCE_LABELS_DIR, label_filename)

        # Move the image
        shutil.move(img_path, os.path.join(img_dest, img_filename))

        # Move the label
        shutil.move(label_path, os.path.join(label_dest, label_filename))

# --- 6. RUN THE FUNCTION ---
print("\nMoving training files...")
move_files(train_images, TRAIN_IMG_DEST, TRAIN_LABEL_DEST)

print("Moving validation files...")
move_files(val_images, VAL_IMG_DEST, VAL_LABEL_DEST)

print("\nAll files have been moved successfully!")

"""Creates a human-readable text file with configuration settings.


**YOLO Requirement:** The YOLO engine needs one central map. The file tells the engine the root path of the data, the location of train/ and val/ subfolders and list of 16 class names (the 16 food items).

"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile /content/drive/MyDrive/sohl_final_data.yaml
# 
# # Path to the root dataset folder
# path: /content/drive/MyDrive/sohl-dataset-split
# 
# # Define the splits (relative to the path)
# train: images/train
# val: images/val
# # We don't have a test set, which is fine for training.
# 
# # Class names
# names:
#   0: bread_or_Roti_naan
#   1: curry_dish
#   2: rice_dish
#   3: dry_vegetable
#   4: snack_item
#   5: sweet_item
#   6: accompaniment
#   7: Dal_or_sambar
#   8: drink
#   9: eggs
#   10: fish_dish
#   11: fruits
#   12: pasta
#   13: salad
#   14: soup
#   15: south_indian_breakfast

!pip install ultralytics

"""Initializes the optimization process using the data from the .yaml file for 50 epochs on the GPU.

This is the core learning phase. The model adjusts millions of parameters based on the differences between its prediction and your ground truth labels (.txt files) until the prediction error (loss) is minimized.

"""

from ultralytics import YOLO

# Load a pre-trained model (yolov8n.pt is small and fast)
model = YOLO("yolov8n.pt")

# Train the model!
print("Starting model training... this will take a while.")
results = model.train(
    data="/content/drive/MyDrive/sohl_final_data.yaml",
    epochs=50,
    imgsz=640,
    project="/content/drive/MyDrive/food_detector_project" # Save results to your Drive
)

print("---")
print("TRAINING COMPLETE! You did it, Riya!")
print("---")

"""Loads your final, trained weights (the "brain") from your Drive.

This is the most accurate model saved from your 50-epoch run. We need to load it into memory before using it.

def detect_food(...) -> Defines the Python function to be called later. This creates the required API (detect_food(image)) for furthur processing.
"""

from ultralytics import YOLO
from PIL import Image

# --- 1. LOAD YOUR TRAINED MODEL ---
# This is the "brain" you just created.
model_path = "/content/drive/MyDrive/food_detector_project/train/weights/best.pt"
model = YOLO(model_path)

print("Successfully loaded your trained model!")

# --- 2. DEFINING FUNCTION ---
def detect_food(image_path):
    """
    This function takes a path to an image, runs it through
    your trained YOLOv8 model, and prints the detections.
    """
    print(f"\nDetecting food in: {image_path}")

    # Run inference on the image
    results = model(image_path)

    # Get the first result (since we're only sending one image)
    result = results[0]

    # Get the bounding boxes and class names
    boxes = result.boxes.xyxy  # Bounding box coordinates
    class_ids = result.boxes.cls # Class IDs

    # Get the human-readable class names
    class_names = result.names

    print(f"Found {len(boxes)} items!")

    # Loop through each detection and print it
    for i in range(len(boxes)):
        x1, y1, x2, y2 = boxes[i]
        class_id = int(class_ids[i])
        class_name = class_names[class_id]

        print(f"  - Item {i+1}: {class_name}")
        print(f"    Coordinates: [x1: {x1:.0f}, y1: {y1:.0f}, x2: {x2:.0f}, y2: {y2:.0f}]")

    return result

"""results = model(image_path)
Runs the detection process on the input image.

The model takes the raw pixels, passes them through its layers, and spits out its final verdict on what objects are present and where they are located in the image space
"""

import os
import glob
from PIL import Image

# 1. Find a test image from your CORRECT validation set
# We look into the 'images/val' folder
val_images_list = glob.glob("/content/drive/MyDrive/sohl-dataset-split/images/val/*.jpg")

if len(val_images_list) > 0:
    # Get the path to the very first image in the list
    my_test_image = val_images_list[0]
    print(f"Using this image from your 'val' folder: {my_test_image}")

    # 2. Run your function!
    # The 'detect_food' function is defined, and 'model' is loaded.
    detection_results = detect_food(my_test_image)

    print("\nDetection complete! Displaying result...")

    # 3. Display the image with the boxes and labels
    # YOLO's plot() function draws the bounding boxes and returns an image array
    Image.fromarray(detection_results.plot()[..., ::-1])

else:
    print("ERROR: Could not find any images in the 'val' folder.")

!cat /content/drive/MyDrive/food_detector_project/train/results.csv | head -n 2

"""mAP50 close to 0.60 (60%) or higher, which is a great result!

"""